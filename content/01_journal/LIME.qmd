---
title: "LIME"
author: "Fadel Victor Shanaa"
---

**Challenge question:**

This is a two part challenge:

Part 1: Recreate plot_features(). Take the explanation data and use the first case to create a plot similar to the output of plot_features().

***Sample Code***


explanation %>% 
  as.tibble()
  
case_1 <- explanation %>%
    filter(case == 1)

case_1 %>%
    plot_features()
    
    
***Sample Code End***

You will need at least the layers geom_col() and coord_flip().

**Bonus Objectives:**

Get your custom plot_features() function to scale to multiple cases
Use theme arguments to modify the look of the plot

**Part 2: Recreate plot_explanations():**

Take the full explanation data and recreate the second plot.

You will need at least the layers geom_tile() and facet_wrap().

**LIME Code Base: **

```{r}
# Load the libraries

suppressMessages(library(h2o))
suppressMessages(library(recipes))
suppressMessages(library(readxl))
suppressMessages(library(tidyverse))
suppressMessages(library(tidyquant))
suppressMessages(library(lime))
suppressMessages(library(rsample))
suppressMessages(library(knitr))


# Create the function to process HR data and make it more readable 
# as a merged data table
process_hr_data_readable <- function(data, definitions_tbl) {
  
  definitions_list <- definitions_tbl %>%
    fill(...1, .direction = "down") %>%
    filter(!is.na(...2)) %>%
    separate(...2, into = c("key", "value"), sep = " '", remove = TRUE) %>%
    rename(column_name = ...1) %>%
    mutate(key = as.numeric(key)) %>%
    mutate(value = value %>% str_replace(pattern = "'", replacement = "")) %>%
    split(.$column_name) %>%
    map(~ select(., -column_name)) %>%
    map(~ mutate(., value = as_factor(value))) 
  
  for (i in seq_along(definitions_list)) {
    list_name <- names(definitions_list)[i]
    colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, "_value"))
  }
  
  
  data_merged_tbl <- list(HR_Data = data) %>%
    append(definitions_list, after = 1) %>%
    reduce(left_join) %>%
    select(-one_of(names(definitions_list))) %>%
    set_names(str_replace_all(names(.), pattern = "_value", 
                              replacement = "")) %>%
    select(sort(names(.))) %>%
    mutate_if(is.character, as.factor) %>%
    mutate(
      BusinessTravel = BusinessTravel %>% fct_relevel("Non-Travel", 
                                                      "Travel_Rarely", 
                                                      "Travel_Frequently"),
      MaritalStatus  = MaritalStatus %>% fct_relevel("Single", 
                                                     "Married", 
                                                     "Divorced")
    )
  
  return(data_merged_tbl)
  
}

# Load the employee attrition data and raw definitions data we had from the AutoML Challenge
employee_attrition_tbl <- read_csv("C:\\Users\\fvsha\\Documents\\GitHub\\ss23-bdml-VictorReaver1999\\AutoML\\HR-Employee-Attrition.csv")
definitions_raw_tbl    <- read_excel("C:\\Users\\fvsha\\Documents\\GitHub\\ss23-bdml-VictorReaver1999\\AutoML\\data_definitions.xlsx", sheet = 1, col_names = FALSE)

# Run the function we created on the data we just loaded
employee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)

# Split the data into test and train sets
set.seed(seed = 1113)
split_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)

# Assign the newly created training and test data
train_readable_tbl <- training(split_obj)
test_readable_tbl  <- testing(split_obj)

# Create a recipe (as in the Business Case)
recipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%
  step_zv(all_predictors()) %>%
  step_mutate_at(c("JobLevel", "StockOptionLevel"), fn = as.factor) %>% 
  prep()

# Apply the recipe
train_tbl <- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)

# Initialize H2O
h2o.init()

# Split data into train, validate, and test for H2O
split_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)
train_h2o <- split_h2o[[1]]
valid_h2o <- split_h2o[[2]]
test_h2o  <- as.h2o(test_tbl)

# Set the target and predictors
y <- "Attrition"
x <- setdiff(names(train_h2o), y)

# Run the AutoML model and save the results
automl_models_h2o <- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 30,
  nfolds            = 5 
)

# Save the best model in the automl_leader variable
automl_leader <- automl_models_h2o@leader

# Create the explainer as in the Business Case
explainer <- train_tbl %>%
  select(-Attrition) %>%
  lime(
    model           = automl_leader,
    bin_continuous  = TRUE,
    n_bins          = 4,
    quantile_bins   = TRUE
  )

explainer

# Create the explanation
explanation <- test_tbl %>%
  slice(1:20) %>%
  select(-Attrition) %>%
  lime::explain(
    
    # Pass our explainer object
    explainer = explainer,
    # Because it is a binary classification model: 1
    n_labels   = 1,
    # number of features to be returned
    n_features = 8,
    # number of localized linear models
    n_permutations = 5000,
    # Let's start with 1
    kernel_width   = 1
  )

explanation

# Convert the explanation into a table
explanation %>% 
  as.tibble()

# Filter out the 1st case
case_1 <- explanation %>%
  filter(case == 1)

# Extract the plot features
case_1 %>%
  plot_features()

# Plot the 1st case
case_1_plot <- case_1 %>%
  ggplot(aes(y=feature_desc, x =feature_weight)) +
  geom_col(aes(fill = feature_weight > 0)) +
  xlab("Weight") + 
  ylab("Feature") +
  scale_fill_discrete(name = "", labels = c("Contradicts", "Supports")) +
  theme(legend.position = "bottom")

ggsave("case_1_plot.png", case_1_plot)

case_1_plot

# Plot the explanation
explanation_plot <- explanation %>%
  mutate(case = as.double(case)) %>%
  ggplot(aes(y=feature_desc, x =case, fill = feature_weight)) +
  geom_tile() +
  facet_wrap(~label) 

ggsave("explanation_plot.png", explanation_plot)

explanation_plot
```

**End of LIME Challenge**